{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import spacy\n",
    "import textacy\n",
    "%matplotlib inline\n",
    "np.random.seed(32113)\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as XGB\n",
    "import string\n",
    "parser = English()\n",
    "import data_prep_new as dp\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading reviews and meta data\n",
    "path = './data/reviews_Home_and_Kitchen.json.gz'\n",
    "meta_path = './data/meta_Home_and_Kitchen.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before creating  a model:\n",
    "In order to create an accurate model, we want to filter reviews.  \n",
    "we filter review by looking at categories of product in meta data. \n",
    "  \n",
    "Below are codes to check products associated with review data.\n",
    "It displays types of categories and number of 'Home & Kitchen' products that are associated with each category.  \n",
    "As you can see, there are many 'Home & kitchen' products  \n",
    "that are associated with categories that are unrelated to Home & Kitchen. \n",
    "By looking at this list, we can decide how to filter products.  \n",
    "  \n",
    "In this case, I would filter out categories where total number is less than 2000.  \n",
    "If you want to strictly work on Home & kitchen products, I will filter out categories less than 10000.  \n",
    "\n",
    "Once we merge review data and meta data, we will filter out reviews by these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             asin  salesRank   imUrl  categories   title  \\\n",
      "rank_keys                                                                  \n",
      "Appliances                     68         68      68          68      68   \n",
      "Arts, Crafts & Sewing        1776       1776    1776        1776    1776   \n",
      "Automotive                     38         38      38          38      11   \n",
      "Baby                          153        153     153         153     153   \n",
      "Beauty                        604        604     604         604     604   \n",
      "Books                           1          1       1           1       1   \n",
      "Camera &amp; Photo             60         60      60          60      60   \n",
      "Cell Phones & Accessories       8          8       8           8       8   \n",
      "Clothing                     1489       1489    1489        1489    1489   \n",
      "Computers & Accessories        12         12      12          12      12   \n",
      "Electronics                   671        671     671         671     671   \n",
      "Grocery & Gourmet Food         15         15      15          15      15   \n",
      "Health & Personal Care       3734       3734    3734        3734    3734   \n",
      "Home & Kitchen              22913         92   22542       22913   21394   \n",
      "Home &amp; Kitchen         212881     212881  212881      212881  212866   \n",
      "Home Improvement              488        488     488         488     488   \n",
      "Industrial & Scientific      3632       3632    3632        3632    3632   \n",
      "Jewelry                       186        186     186         186     186   \n",
      "Kitchen & Dining           176767     176767  176767      176767  176759   \n",
      "Musical Instruments           132        132     132         132     132   \n",
      "Office Products                70         70      70          70      70   \n",
      "Patio, Lawn & Garden         2190       2190    2190        2190    2190   \n",
      "Pet Supplies                  490        490     490         490     490   \n",
      "Shoes                         413        413     413         413     413   \n",
      "Software                       52         52      52          52       1   \n",
      "Sports &amp; Outdoors        3869       3869    3869        3869    3869   \n",
      "Toys & Games                 4141       4141    4141        4141    4141   \n",
      "Video Games                   120        120     120         120       1   \n",
      "Watches                        15         15      15          15      15   \n",
      "\n",
      "                           description   price  brand  related  rank_values  \n",
      "rank_keys                                                                    \n",
      "Appliances                          68      59     52       68           68  \n",
      "Arts, Crafts & Sewing             1706    1429    822     1357         1776  \n",
      "Automotive                          36      35      9       38           38  \n",
      "Baby                               153     145     86      148          153  \n",
      "Beauty                             557     444    208      482          604  \n",
      "Books                                0       0      0        0            1  \n",
      "Camera &amp; Photo                  55      51     14       53           60  \n",
      "Cell Phones & Accessories            8       7      1        7            8  \n",
      "Clothing                             2     857    272      957         1489  \n",
      "Computers & Accessories             12      11      8       11           12  \n",
      "Electronics                        621     421    166      441          671  \n",
      "Grocery & Gourmet Food              15      15     12       15           15  \n",
      "Health & Personal Care            3479    2547   1446     2682         3734  \n",
      "Home & Kitchen                   19809   14750   7906    14220        22913  \n",
      "Home &amp; Kitchen              197148  135866  62958   141897       212881  \n",
      "Home Improvement                   488     436    364      425          488  \n",
      "Industrial & Scientific           3520    3143   1579     3092         3632  \n",
      "Jewelry                              0     134      7      132          186  \n",
      "Kitchen & Dining                167909  117484  72241   126992       176767  \n",
      "Musical Instruments                123     111     50      104          132  \n",
      "Office Products                     70      57     45       56           70  \n",
      "Patio, Lawn & Garden              2099    1591   1042     1695         2190  \n",
      "Pet Supplies                       470     382    205      334          490  \n",
      "Shoes                                0     182     38      277          413  \n",
      "Software                            44      28      1       30           52  \n",
      "Sports &amp; Outdoors             3571    2433   1473     2426         3869  \n",
      "Toys & Games                      3742    2450   1602     2806         4141  \n",
      "Video Games                         88      89      0      100          120  \n",
      "Watches                              0      11      4       12           15  \n"
     ]
    }
   ],
   "source": [
    "#run this code if you do not know if products belong to unrelated categories\n",
    "df_test = dp.Data_prep1(path)\n",
    "meta = dp.getDF(meta_path)\n",
    "meta = dp.add_meta_info(df_test,meta,'Home & Kitchen',20,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data, Cleaning Meta data  \n",
    "the function **df_prep1** will do three things for you:  \n",
    "1. Cleaning meta data for you (gets rid of Nan values)  \n",
    "2. Add features created from Meta data (categories, sales ranking within the categories and price)   \n",
    "3. Filter out categories that are not associated with the data topics  \n",
    "4. Merge meta data with review datas and output pandas dataframe \n",
    "5. reassign values of 'helpful' features into 2 values and calculate percentage of positive votes on a review.  \n",
    "  \n",
    "inputs:  \n",
    "**dp.df_prep1( a , b , c , d )**  \n",
    "a = path of your review data (json.gz format)  \n",
    "b = path of your meta data (json.gz format)  \n",
    "c = topic keys: category names that every product in your dataset is associated with.  \n",
    "for example: 'Video Games', 'Home &amp; Kitchen' etc.  \n",
    "d = filtering out categoiry if the total number of product associated with that category is less than this number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average price for Home &amp; Kitchen is $129.110169121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data_prep_new.py:890: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_topic['price'] = df_topic['price'].fillna(average_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average price for Home & Kitchen is $132.971979089\n",
      "average price for Kitchen & Dining is $77.4992568967\n",
      "--- 778.562792063 seconds ---\n"
     ]
    }
   ],
   "source": [
    "df= dp.df_prep1(path, meta_path,'Home & Kitchen',5000)\n",
    "# should spit out average price for each category.  \n",
    "# these price will be filling Nan under price feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test dataset:\n",
    "In NLP prediction model, it is safe to run train and test dataset before running model building functions.  \n",
    "Here, we are randomly selecting 85% of data as a train dataset.  \n",
    "and assign rest of the data as test dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = df.index\n",
    "random_ind = np.random.choice(list(ind), int(len(df)*.85), replace=False)\n",
    "df_train = df.loc[list(random_ind)]\n",
    "test_ind = [i for i in ind if i not in random_ind]\n",
    "df_test = df.loc[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## if you want to save test and training dataframe...\n",
    "#df_test.to_pickle(\"./HomeandKitchen_df_test_15percent.pkl\")\n",
    "#df_train.to_pickle(\"./HomeandKitchen_df_train_85percent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf model\n",
    "**df_prep_train1** function creates tfidf matrix and tfidf sklearn model.  \n",
    "It also saves tfidf matrix and tfidf skearn model as a pickle file in case something happens later.  \n",
    "  \n",
    "inputs:\n",
    "**df_prep_train1( a , b , c(optional) )**  \n",
    "a = your training dataframe created above  \n",
    "b = filename/keyword. this string will be used to name tfidf matrix and tfidf sklearn model pickle file.  \n",
    "c = a list containing parameters of TfidfVectorizer sklearn class. this is optional.  \n",
    "default values for this input is:  tfidf_set = [2,0.95,10000,'l2']  \n",
    "  \n",
    "where TfidfVectorizer(stop_words=STOPLIST, tokenizer=lemma, min_df=tfidf_set[0], max_df=tfidf_set[1], max_features =tfidf_set[2], norm=tfidf_set[3])  \n",
    "  \n",
    "visit Sklearn web for more details.     \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 698.633850813 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix, tfidf_model  = dp.df_prep_train1(df_train,'HomeAndKitchen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before running NMF, check your elbow!\n",
    "the function **NMF_elbow** will give you stats about reconstruction error for different K component.  \n",
    "you want to chose right K where slope changes significantly.  \n",
    "Since the data we are using does not have obvious elbow,  \n",
    "I added error difference between K and error of each K.  \n",
    "\n",
    "inputs:  \n",
    "**NMF_elbow( a , b )**  \n",
    "a = your tfidf matrix  \n",
    "b = range of K (list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated in 162.172966003 seconds \n",
      "\n",
      "\n",
      "error difference\n",
      "1.07929379637\n",
      "0.858621313474\n",
      "0.789527637731\n",
      "0.815067794558\n",
      "0.658543930188\n",
      "0.595061152613\n",
      "0.562621833959\n",
      "0.550520568273\n",
      "0.527111543583\n",
      "0.446938722788\n",
      "\n",
      "\n",
      "error k = 1: 259.161844291\n",
      "error k = 2: 258.082550495\n",
      "error k = 3: 257.223929181\n",
      "error k = 4: 256.434401544\n",
      "error k = 5: 255.619333749\n",
      "error k = 6: 254.960789819\n",
      "error k = 7: 254.365728666\n",
      "error k = 8: 253.803106832\n",
      "error k = 9: 253.252586264\n",
      "error k = 10: 252.72547472\n",
      "error k = 11: 252.278535998\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCoSIiORIBUJERHL0f7IrLxD2AyyvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f031597c7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.NMF_elbow(tfidf_matrix, range(1,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding NMF results and tfidf results onto training dataset\n",
    "**df_prep_train2** function does lots of things here.\n",
    "1. calculate NMF from the tfidf matrix that you created from df_prep_train1\n",
    "2. add NMF results as features (predict percentage values for each NMF topics)\n",
    "3. print outs top 20 words that are highly associated with each NMF topics.\n",
    "4. add tfidf results to training dataset  \n",
    "(you can select how many words you want to add to the data frame by choosing values for max_feat (e))  \n",
    "5. saves resulting training dataframe, NMF model and tfidf feature model as pickle files\n",
    "\n",
    "inputs:  \n",
    "**df_prep_train2**( a , b , c , d , e (opt) , f (opt), g (opt))  \n",
    "a = training dataframe.  \n",
    "b = filename/keyword. this string will be used to name NMF model and tfidf feature model pickle file.  \n",
    "c = tfidf matrix.\n",
    "d = tfidf model.  \n",
    "e = max feature (optional). default value = 1000. \n",
    "will create tfidf model with top 1000 (default) words   \n",
    "and create features of these top 1000 words in your training dataframe.  \n",
    "f = NMF parameters (optional). default values NMF_set = [6,'cd',0.1,0.5].  \n",
    "where NMF(n_components=NMF_set[0], solver=NMF_set[1], random_state=32113, alpha=NMF_set[2], l1_ratio=NMF_set[3])  \n",
    "visit Sklearn web for more details.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html  \n",
    "\n",
    "g = tfidf parameters (optional). default values = [2,0.95,10000,'l2'].  \n",
    "  \n",
    "where TfidfVectorizer(stop_words=STOPLIST, tokenizer=lemma, min_df=tfidf_set[0], max_df=tfidf_set[1], max_features =tfidf_set[2], norm=tfidf_set[3])  \n",
    "visit Sklearn web for more details.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html  \n",
    "(3rd value will be replaced by max feature (e))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "machine blender ice use make juicer juice cream bowl mixer clean blade easy food bread time fruit smoothie good dough\n",
      "Topic #1:\n",
      "coffee cup water maker machine brew filter grind carafe grinder espresso hot ground pot make bean use pour mug taste\n",
      "Topic #2:\n",
      "vacuum carpet floor clean dyson dirt bag suction hair brush dust cleaner attachment hose use canister pick hoover vac filter\n",
      "Topic #3:\n",
      "knife blade sharp set sharpen cut edge chef sharpener handle slice steel block use henckel wusthof good steak hand dull\n",
      "Topic #4:\n",
      "pan stick cook non use heat cookware pot egg set oil iron food grill handle cast skillet clean surface calphalon\n",
      "Topic #5:\n",
      "mattress bed pillow sleep sheet foam memory pad night topper soft comfortable feel firm cover like smell queen wake good\n",
      "Topic #6:\n",
      "rice cooker cook pot pressure slow brown cooking steam cup water lid time use warm crock food make steamer minute\n",
      "Topic #7:\n",
      "unit fan air room water heater filter heat cool run window temperature work low turn quiet use high noise setting\n",
      "Topic #8:\n",
      "oven toaster toast bread cook pizza convection bake bagel use microwave timer rack slice burn heat setting time door tray\n",
      "Topic #9:\n",
      "product buy look item amazon use good like make purchase order review work return set say price quality time great\n",
      "--end--\n",
      "--- 721.657060146 seconds ---\n"
     ]
    }
   ],
   "source": [
    "df_train_new,NMF_model,TFIDF_feat_model = dp.df_prep_train2(df_train, 'HomeAndKitchen', tfidf_matrix, tfidf_model,1000, [10,'cd',0.1,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## in case you need to load each model, you can load models here\n",
    "\n",
    "## df_prep1/train-test split result\n",
    "#df_train = pd.read_pickle('./HomeandKitchen_df_train_85percent.pkl')\n",
    "#df_test = pd.read_pickle('./HomeandKitchen_df_test_15percent.pkl')\n",
    "\n",
    "## df_prep_train1 results\n",
    "# with open(r\"HomeAndKitchen_tfidf_matrix.pickle\", \"rb\") as input_file:\n",
    "#     tfidf_matrix = pickle.load(input_file)\n",
    "# with open(r\"HomeAndKitchen_tfidf_model.pickle\", \"rb\") as input_file:\n",
    "#     tfidf_model= pickle.load(input_file)\n",
    "\n",
    "## df_prep_train2 results\n",
    "df_train_new = pd.read_pickle('./preped_HomeAndKitchen_max_feature1000.pkl')\n",
    "# with open('HomeAndKitchen_NMF_model.pickle', \"rb\") as input_file:\n",
    "#     NMF_model = pickle.load(input_file)\n",
    "# with open(r\"HomeAndKitchen_tfidf_feat_model.pickle\", \"rb\") as input_file:\n",
    "#     TFIDF_feat_model= pickle.load(input_file)\n",
    "df_test_new = pd.read_pickle('./preped_HomeAndKitchen_df_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test dataset\n",
    "\n",
    "Now we want to prepare test dataset.  \n",
    "I simply used MNF and tfidf models of training dataset to transform test dataset.  \n",
    "\n",
    "\n",
    "**df_prep_test** function adds features for test data.  \n",
    "It uses transform method of NMF and tfidf models that we just trained with training dataset.  \n",
    "The function outputs test dataframe which contains same amount of features as training dataframe.  \n",
    "It also saves output dataframe as a pickle file.  \n",
    "\n",
    "inputs:  \n",
    "**df_prep_test**( a , b , c , d , e )  \n",
    "a = test dataframe we created previously. (read Split train and test dataset section above)  \n",
    "b = tfidf model trained with training dataframe.  \n",
    "c = NMF model that was trained with training dataframe.\n",
    "d = second tfidf model that is used to create tfidf term features.  \n",
    "e = filename/keywords used as a name of pickle file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         reviewerID        asin  \\\n",
      "2    A1SMVFN1Y9DZXW  0615391206   \n",
      "5    A1ZH5ULI4SBO48  0615391206   \n",
      "22    ARESXT9CAOJRZ  0912696591   \n",
      "29   A1PXUBSIWVVE10  492120523X   \n",
      "32   A2E5BU9CSIN7GM  722104810X   \n",
      "64   A31NQ3ELMQ9MGJ  B00000JGRP   \n",
      "81   A3TAB1MAWJ163V  B00000JGRQ   \n",
      "92   A2UGCWC46V7PPG  B00000JGRT   \n",
      "94   A3EV60RHD55U6D  B00000JGRT   \n",
      "95    AZ3G48WRWSOBG  B00000JGRT   \n",
      "96   A26PEAFQULPQ3F  B00000JGRT   \n",
      "98    AEPWXJ5SR5RZS  B00000JGRT   \n",
      "113  A2NI216EHE16Y5  B00000JGRT   \n",
      "114   ABCEUIYQX88D2  B00000JGRT   \n",
      "124   AC1P6DPW3VKSD  B00000JGRT   \n",
      "128  A1NNJGZEFCAQ1Y  B00000JGRT   \n",
      "132  A2A1NHMIM8QR7T  B00000JGRT   \n",
      "133  A24DOLVPI9TS2K  B00000JGRT   \n",
      "135   A1QO6YNSZSASA  B00000JGRT   \n",
      "147  A2BD904DKSRS17  B00000JGRT   \n",
      "185  A1VVW329KUH9GB  B00002N602   \n",
      "187   A2NXLMNPSZ6P0  B00002N602   \n",
      "202  A2YK3OALZ48XPF  B00002N602   \n",
      "205  A2E0H4VM4OL0HI  B00002N602   \n",
      "215  A30YP1B6XWP3S4  B00002N602   \n",
      "224  A3CFJWL546QP8O  B00002N62E   \n",
      "332   A95C57OS8MIFX  B00002ND6A   \n",
      "333    AYQJC0CDQTSW  B00002ND6A   \n",
      "342  A3UOK6S7SQU7G6  B00002ND6A   \n",
      "382  A12DP14GPRZF7E  B00004OCJK   \n",
      "..              ...         ...   \n",
      "626  A27HC4H118L5ID  B00004R8ZD   \n",
      "629  A179NPGNW9NOC7  B00004R8ZD   \n",
      "633  A28AOYX0UWTI66  B00004R8ZE   \n",
      "647   APCULF3ISBHRH  B00004R8ZE   \n",
      "659  A3OD5ZLXNMPL8H  B00004R8ZE   \n",
      "665  A3F69HNLEEWH11  B00004R8ZE   \n",
      "675  A19HJ9N30HFUW0  B00004R8ZE   \n",
      "677  A1ESGQN8S3LL1S  B00004R8ZE   \n",
      "683   AAPFN1BADMWMC  B00004R90W   \n",
      "688   AC64J76R8B1M9  B00004R90X   \n",
      "691  A2QYV4XKCRWCI2  B00004R90Y   \n",
      "697  A281NPSIMI1C2R  B00004R911   \n",
      "698   A3ZSU5099VSPR  B00004R913   \n",
      "709  A1115ST6F5CWYP  B00004R91I   \n",
      "712  A3ETOYIJX7WHFM  B00004R91I   \n",
      "713  A1F4J8EM5XHT0B  B00004R91J   \n",
      "718  A1KXONFPU2XQ5K  B00004R91J   \n",
      "730  A3TS6MZ6XXDL7X  B00004R923   \n",
      "731  A1SX9HXKKGYUFR  B00004R923   \n",
      "732  A3F0DEUYQWU1QM  B00004R92B   \n",
      "734  A1JKGITO676QV7  B00004R92D   \n",
      "736  A1HR5GD9HUN9IW  B00004R92G   \n",
      "742  A3B6E2WUEKE9WK  B00004R92L   \n",
      "743   AXYIOXWONOO1N  B00004R92L   \n",
      "754  A3LYE5I2ZZGII0  B00004R92N   \n",
      "773  A1QTIQP307ERN3  B00004R932   \n",
      "776   AZTYASK6KKNY1  B00004R936   \n",
      "779  A2RH8APY5IR7NX  B00004R936   \n",
      "793  A3FTI86WAVJOLG  B00004R93H   \n",
      "800  A2APXLDQ0J71K1  B00004R93N   \n",
      "\n",
      "                                            reviewText  overall  \\\n",
      "2    Really, it's impossible to live without this b...      5.0   \n",
      "5    I bought this when I bought the pop maker. I t...      2.0   \n",
      "22   Unless you are a professional cake maker, I th...      4.0   \n",
      "29   Got my order at last after 6 months, WELL wort...      5.0   \n",
      "32   I used this product to make a mini apple pie. ...      1.0   \n",
      "64   I purchased this chopper when I gave my old tr...      1.0   \n",
      "81   I just got this yesterday from Amazon.  I was ...      2.0   \n",
      "92   Works very well--but [at the price]? Come on! ...      2.0   \n",
      "94   I purchased this in kind of a throwaway moment...      5.0   \n",
      "95   The product works as advertised.  Definitely f...      5.0   \n",
      "96   I asked my husband to buy this machine for me ...      5.0   \n",
      "98   This is just the right size for my husband and...      5.0   \n",
      "113  There are very few flaws I can find about this...      5.0   \n",
      "114  My partner, my son, my grandson and daughter-i...      5.0   \n",
      "124  I love my Cuisinart Frozen Yogurt Maker.  So m...      3.0   \n",
      "128  I bought a refurbished model and then had seco...      5.0   \n",
      "132  I picked this up at the start of summer. i've ...      4.0   \n",
      "133  I bought this item and thought that it would m...      1.0   \n",
      "135  I bought this unit based on the positive revie...      1.0   \n",
      "147  I've had this ice-cream maker for three years ...      5.0   \n",
      "185  I have been using Presto Pressure Cookers for ...      5.0   \n",
      "187  This was purchased to replace an 8 quart alumi...      1.0   \n",
      "202  I bought this cooker 6 months ago from amazon ...      5.0   \n",
      "205  I couldn't believe it even cooks some traditio...      5.0   \n",
      "215  My mother bought me this nearly exact cooker m...      5.0   \n",
      "224  I remember from a very young age my parents ma...      5.0   \n",
      "332  I love this ice cream machine!  It makes enoug...      5.0   \n",
      "333  Purchased the 6 qt White Mountain in July of 2...      1.0   \n",
      "342  I'm a novice to Ice Cream making. My family an...      5.0   \n",
      "382  This wire potato masher, like the rest of the ...      5.0   \n",
      "..                                                 ...      ...   \n",
      "626  My wife and I find this to be the best can ope...      5.0   \n",
      "629  My husband drove me nuts looking for one of th...      5.0   \n",
      "633  I enjoy a nice home cooked meal; but with work...      5.0   \n",
      "647  I had the pleasure to work in Switzerland for ...      5.0   \n",
      "659  When I decided I wanted to buy a pressure cook...      5.0   \n",
      "665  When my old pressure cooker broke, I thought I...      2.0   \n",
      "675  Thanks to this pressure cooker, and Lorna Sass...      5.0   \n",
      "677  Was about to get another slow cooker but thoug...      5.0   \n",
      "683  Am I the only person who ever bought this and ...      4.0   \n",
      "688  I have been making my own corn tortillas and t...      3.0   \n",
      "691  This is a great set of Tostada Salad Shell / T...      5.0   \n",
      "697  Since Mini-Yorkshire puddings and popovers are...      5.0   \n",
      "698  All cookie sheets I buy in the stores for the ...      5.0   \n",
      "709  If you love to bake, you will love this pan.  ...      5.0   \n",
      "712  This is the second one that I have bought.  I'...      5.0   \n",
      "713  To get the size and the nice crispy crust that...      1.0   \n",
      "718  This has to be my favorite pan for making the ...      5.0   \n",
      "730  I am pleased with the quality of the grid.  Ho...      2.0   \n",
      "731  This is by far the best cooling rack that I ha...      5.0   \n",
      "732  I love my new Choco Latte machine.  It has all...      5.0   \n",
      "734  My wife was using the oven to make garlic toas...      1.0   \n",
      "736  The snackster is the best appliance in my kitc...      5.0   \n",
      "742  It looks weird to most american kitchens.  A b...      5.0   \n",
      "743  I use one of these regularly and for measuring...      3.0   \n",
      "754  We have used ours at least five times a day fo...      5.0   \n",
      "773  After breaking carafes several times @ $23.00/...      5.0   \n",
      "776  I loved my first Melitta Mill & Brew, which I ...      3.0   \n",
      "779  I had great hopes when I opened the box, but a...      2.0   \n",
      "793  You know, it's funny because I wanted this thi...      5.0   \n",
      "800  I don't have to run around like a madwoman try...      5.0   \n",
      "\n",
      "                                               summary  helpful_total_review  \\\n",
      "2                           a MUST if you own the ZOKU                  33.0   \n",
      "5    Okay but you can figure it out yourself withou...                  39.0   \n",
      "22          All You Need to Know about Cake Decorating                  27.0   \n",
      "29                     Manga=Magic.  TOTALLY worth it.                  21.0   \n",
      "32                                           pie maker                  27.0   \n",
      "64                             Really Bad Mini Chopper                  54.0   \n",
      "81                                             Plastic                  47.0   \n",
      "92                             Good product, bad price                  36.0   \n",
      "94                Ready and easy right out of the box!                  44.0   \n",
      "95                         Cuisinart Ice Cream Machine                  32.0   \n",
      "96                Easy to use and makes GREAT product!                 604.0   \n",
      "98                                 Wonderful Ice Cream                  34.0   \n",
      "113  Top notch powerful icecream maker for the home...                 100.0   \n",
      "114      Great! Very little work - wonderful results!!                  28.0   \n",
      "124                             Wish it worked better.                  24.0   \n",
      "128                                   I'm so impressed                  21.0   \n",
      "132                    make your own premium ice cream                 221.0   \n",
      "133                             Item Not as advertise.                  30.0   \n",
      "135      Check the return policy and keep your receipt                  82.0   \n",
      "147               Pays for itself in one summer of use                  21.0   \n",
      "185             The best pressure cooker on the market                  34.0   \n",
      "187  Disappointing, especially compared to other Pr...                  25.0   \n",
      "202                         great value, sturdy cooker                 559.0   \n",
      "205                          Way beyond expectation!!!                  27.0   \n",
      "215                  Great no frills pressure cooker!!                  62.0   \n",
      "224                        Incredible customer service                  25.0   \n",
      "332   Painless Way To Make Lots of Wonderful Ice Cream                 169.0   \n",
      "333                                Way overpriced junk                  30.0   \n",
      "342                                   Quality bar none                  41.0   \n",
      "382               Outstanding quality and great price.                  54.0   \n",
      "..                                                 ...                   ...   \n",
      "626                             Why I Love This Opener                 149.0   \n",
      "629                   Fabulous, Must Have Kitchen Tool                  24.0   \n",
      "633                        My first pressure Cooker...                  45.0   \n",
      "647                                      swiss quality                  24.0   \n",
      "659                                     A GREAT COMBO!                  27.0   \n",
      "665               NOT WORTH THE MONEY~ SERIOUSLY FOLKS                  73.0   \n",
      "675                              Can't live without it                  31.0   \n",
      "677                  A definite must for every kitchen                  33.0   \n",
      "683                            Not As Easy As It Seems                  43.0   \n",
      "688  Nice idea, but it takes some work to get the t...                  21.0   \n",
      "691             Restaurant Style Taco Salad Shell Pans                  41.0   \n",
      "697                                   Perfect Popovers                  42.0   \n",
      "698                 The best cookie sheet I have owned                  22.0   \n",
      "709                  Fabulous pan, highly recommend!!!                 106.0   \n",
      "712  Must-have if you want to bake your own GF fren...                  22.0   \n",
      "713                             Excellemt french bread                  42.0   \n",
      "718                  Makes your bread crust very crisp                  40.0   \n",
      "730     Don't be fooled by \"Better Together\" promotion                  23.0   \n",
      "731                   Cooling rack with no more crumbs                  57.0   \n",
      "732                             In one word, fabulous!                  28.0   \n",
      "734                                             Lt/Col                  29.0   \n",
      "736                             Spectacular Snackster!                  32.0   \n",
      "742                      An irreplaceable kitchen tool                  53.0   \n",
      "743                        Useful but has design flaws                  21.0   \n",
      "754                          Works great, easy to use.                  27.0   \n",
      "773       Great coffee for hours and thoughtful design                  25.0   \n",
      "776                              Beans won't grind....                  24.0   \n",
      "779                                Inexplicable Design                  24.0   \n",
      "793            Nothing like fresh bread in the morning                  99.0   \n",
      "800                           Cooking is relaxing now!                  27.0   \n",
      "\n",
      "     helpful_percent  text_length   price  rank_values        ...         \\\n",
      "2               0.91        500.0   17.29       3900.0        ...          \n",
      "5               0.82        413.0   17.29       3900.0        ...          \n",
      "22              0.93        297.0   14.26       9690.0        ...          \n",
      "29              0.81        877.0   77.50     911638.0        ...          \n",
      "32              0.04        344.0   16.99     110787.0        ...          \n",
      "64              0.91        946.0   29.95      14534.0        ...          \n",
      "81              0.89        551.0   69.00      18822.0        ...          \n",
      "92              0.75        218.0   62.99       6359.0        ...          \n",
      "94              1.00       1286.0   62.99       6359.0        ...          \n",
      "95              0.94        293.0   62.99       6359.0        ...          \n",
      "96              0.93       1353.0   62.99       6359.0        ...          \n",
      "98              0.97        287.0   62.99       6359.0        ...          \n",
      "113             0.94       7446.0   62.99       6359.0        ...          \n",
      "114             1.00       1128.0   62.99       6359.0        ...          \n",
      "124             0.92        403.0   62.99       6359.0        ...          \n",
      "128             0.95       1580.0   62.99       6359.0        ...          \n",
      "132             0.92       3252.0   62.99       6359.0        ...          \n",
      "133             0.33       1449.0   62.99       6359.0        ...          \n",
      "135             0.88        938.0   62.99       6359.0        ...          \n",
      "147             1.00        671.0   62.99       6359.0        ...          \n",
      "185             0.94        704.0   51.79       2938.0        ...          \n",
      "187             0.96        699.0   51.79       2938.0        ...          \n",
      "202             0.98       2687.0   51.79       2938.0        ...          \n",
      "205             1.00        393.0   51.79       2938.0        ...          \n",
      "215             0.97       1040.0   51.79       2938.0        ...          \n",
      "224             1.00       1473.0  250.49      64596.0        ...          \n",
      "332             0.95        836.0   77.50      89244.0        ...          \n",
      "333             0.97       1209.0   77.50      89244.0        ...          \n",
      "342             1.00       1303.0   77.50      89244.0        ...          \n",
      "382             0.89       1283.0   11.99       2012.0        ...          \n",
      "..               ...          ...     ...          ...        ...          \n",
      "626             0.99       2698.0   19.95      25405.0        ...          \n",
      "629             0.96        704.0   19.95      25405.0        ...          \n",
      "633             0.89       3345.0  179.70      25834.0        ...          \n",
      "647             1.00       1108.0  179.70      25834.0        ...          \n",
      "659             1.00        453.0  179.70      25834.0        ...          \n",
      "665             0.60       1302.0  179.70      25834.0        ...          \n",
      "675             1.00        376.0  179.70      25834.0        ...          \n",
      "677             0.94       2173.0  179.70      25834.0        ...          \n",
      "683             0.86       1306.0   77.50     153982.0        ...          \n",
      "688             0.90        639.0   13.05       8460.0        ...          \n",
      "691             1.00        170.0    9.12       5216.0        ...          \n",
      "697             0.93        378.0   21.95       9736.0        ...          \n",
      "698             1.00        593.0   10.75     289111.0        ...          \n",
      "709             0.98        958.0   21.99      45870.0        ...          \n",
      "712             0.91        665.0   21.99      45870.0        ...          \n",
      "713             0.12        243.0   14.25     117442.0        ...          \n",
      "718             1.00        645.0   14.25     117442.0        ...          \n",
      "730             0.48        349.0   77.50     323717.0        ...          \n",
      "731             0.98        500.0   77.50     323717.0        ...          \n",
      "732             0.96        666.0   77.50     919660.0        ...          \n",
      "734             1.00        438.0   77.50     818084.0        ...          \n",
      "736             0.97        482.0   77.50     327884.0        ...          \n",
      "742             0.96        730.0   12.39      12968.0        ...          \n",
      "743             0.90        334.0   12.39      12968.0        ...          \n",
      "754             1.00        669.0   77.50     809711.0        ...          \n",
      "773             0.96       2795.0   77.50     940333.0        ...          \n",
      "776             0.92        897.0   77.50     138799.0        ...          \n",
      "779             0.54       1507.0   77.50     138799.0        ...          \n",
      "793             0.92       2279.0   77.50     434564.0        ...          \n",
      "800             0.93        416.0   77.50     388867.0        ...          \n",
      "\n",
      "     percent_GROUP_1  percent_GROUP_2  percent_GROUP_3  percent_GROUP_4  \\\n",
      "2           0.007564         0.000000         0.000000         0.000000   \n",
      "5           0.008171         0.001048         0.000000         0.000000   \n",
      "22          0.003978         0.001701         0.000462         0.000000   \n",
      "29          0.008223         0.000000         0.000000         0.000000   \n",
      "32          0.005954         0.000000         0.000000         0.000066   \n",
      "64          0.011321         0.000000         0.000000         0.000000   \n",
      "81          0.000703         0.000000         0.000000         0.000000   \n",
      "92          0.012955         0.000310         0.000000         0.000000   \n",
      "94          0.031360         0.000000         0.000000         0.000000   \n",
      "95          0.019325         0.000000         0.000000         0.000000   \n",
      "96          0.042186         0.000000         0.000000         0.000000   \n",
      "98          0.019311         0.000000         0.000041         0.000000   \n",
      "113         0.038776         0.001697         0.000000         0.000000   \n",
      "114         0.029275         0.000000         0.000000         0.000000   \n",
      "124         0.030986         0.000000         0.000000         0.000000   \n",
      "128         0.036110         0.000000         0.000000         0.000000   \n",
      "132         0.044567         0.000000         0.000000         0.000000   \n",
      "133         0.008577         0.000000         0.000000         0.000000   \n",
      "135         0.013627         0.000000         0.000000         0.000000   \n",
      "147         0.036769         0.000000         0.000000         0.000000   \n",
      "185         0.002225         0.000000         0.000842         0.002190   \n",
      "187         0.000000         0.000000         0.000000         0.000000   \n",
      "202         0.002797         0.004992         0.000138         0.000779   \n",
      "205         0.006655         0.000000         0.000000         0.000000   \n",
      "215         0.009815         0.002536         0.001778         0.001654   \n",
      "224         0.028270         0.000050         0.000000         0.000000   \n",
      "332         0.034666         0.000000         0.000000         0.000000   \n",
      "333         0.018648         0.000000         0.000000         0.000000   \n",
      "342         0.033120         0.000000         0.000000         0.000000   \n",
      "382         0.006107         0.000000         0.000887         0.002057   \n",
      "..               ...              ...              ...              ...   \n",
      "626         0.000992         0.000000         0.000000         0.002413   \n",
      "629         0.000863         0.008416         0.000000         0.001244   \n",
      "633         0.010256         0.000000         0.000000         0.000906   \n",
      "647         0.000596         0.000000         0.000033         0.000000   \n",
      "659         0.000070         0.000000         0.000000         0.000000   \n",
      "665         0.000096         0.000000         0.000897         0.001601   \n",
      "675         0.002648         0.000000         0.000000         0.000000   \n",
      "677         0.002322         0.000000         0.000000         0.000523   \n",
      "683         0.010368         0.000000         0.000000         0.000000   \n",
      "688         0.001197         0.000000         0.000126         0.000000   \n",
      "691         0.007990         0.000000         0.000859         0.000583   \n",
      "697         0.006727         0.000000         0.000000         0.000000   \n",
      "698         0.004305         0.000000         0.000276         0.000000   \n",
      "709         0.003945         0.000000         0.000000         0.006538   \n",
      "712         0.008866         0.000000         0.000000         0.000000   \n",
      "713         0.004945         0.000000         0.000000         0.000000   \n",
      "718         0.005132         0.000000         0.000000         0.000000   \n",
      "730         0.000000         0.000000         0.000000         0.000000   \n",
      "731         0.004474         0.000000         0.000000         0.000000   \n",
      "732         0.016229         0.023044         0.000000         0.000000   \n",
      "734         0.000000         0.000000         0.000000         0.000475   \n",
      "736         0.010908         0.000000         0.000023         0.000427   \n",
      "742         0.008216         0.003958         0.000280         0.000362   \n",
      "743         0.006431         0.004017         0.001327         0.000000   \n",
      "754         0.005764         0.001014         0.001929         0.000000   \n",
      "773         0.000000         0.047896         0.000000         0.000000   \n",
      "776         0.007237         0.008010         0.000000         0.000000   \n",
      "779         0.000000         0.031029         0.000000         0.000000   \n",
      "793         0.017973         0.000000         0.000613         0.000000   \n",
      "800         0.004392         0.000000         0.001231         0.000000   \n",
      "\n",
      "     percent_GROUP_5  percent_GROUP_6  percent_GROUP_7  percent_GROUP_8  \\\n",
      "2           0.000000         0.000000         0.000000         0.000812   \n",
      "5           0.001448         0.000000         0.000000         0.000000   \n",
      "22          0.001994         0.000789         0.000000         0.000206   \n",
      "29          0.001206         0.000235         0.004165         0.000000   \n",
      "32          0.001168         0.000000         0.000000         0.000000   \n",
      "64          0.000000         0.000000         0.000000         0.000000   \n",
      "81          0.000000         0.000000         0.000000         0.000705   \n",
      "92          0.000000         0.000000         0.000000         0.009811   \n",
      "94          0.000000         0.000000         0.000000         0.000000   \n",
      "95          0.000000         0.000000         0.000000         0.001642   \n",
      "96          0.000000         0.000000         0.000000         0.000000   \n",
      "98          0.000000         0.000000         0.000000         0.005365   \n",
      "113         0.000000         0.000000         0.000000         0.000000   \n",
      "114         0.000000         0.000000         0.000000         0.000000   \n",
      "124         0.000000         0.000000         0.000000         0.000000   \n",
      "128         0.000000         0.000000         0.000000         0.000000   \n",
      "132         0.000000         0.000000         0.000000         0.000840   \n",
      "133         0.000000         0.000000         0.000000         0.003672   \n",
      "135         0.000000         0.000000         0.000000         0.016810   \n",
      "147         0.000000         0.000000         0.000000         0.000000   \n",
      "185         0.000000         0.000000         0.031552         0.000000   \n",
      "187         0.000000         0.000000         0.020000         0.000000   \n",
      "202         0.010609         0.000000         0.019359         0.005470   \n",
      "205         0.004113         0.000225         0.015215         0.005261   \n",
      "215         0.000000         0.000000         0.022792         0.003127   \n",
      "224         0.000000         0.000000         0.000000         0.000000   \n",
      "332         0.000000         0.000000         0.000000         0.000000   \n",
      "333         0.000000         0.000000         0.000000         0.002916   \n",
      "342         0.000000         0.000000         0.000000         0.000000   \n",
      "382         0.003215         0.000612         0.001242         0.000000   \n",
      "..               ...              ...              ...              ...   \n",
      "626         0.000000         0.000000         0.000337         0.001181   \n",
      "629         0.000000         0.000000         0.000163         0.000000   \n",
      "633         0.006766         0.000000         0.024277         0.000000   \n",
      "647         0.003410         0.000000         0.019524         0.001722   \n",
      "659         0.000307         0.000000         0.054539         0.000000   \n",
      "665         0.000827         0.000000         0.034514         0.000000   \n",
      "675         0.001526         0.000254         0.022367         0.000000   \n",
      "677         0.012387         0.000649         0.030131         0.001409   \n",
      "683         0.018883         0.000155         0.000000         0.000000   \n",
      "688         0.009408         0.000000         0.000000         0.000000   \n",
      "691         0.002781         0.000000         0.000000         0.000000   \n",
      "697         0.032262         0.000000         0.000000         0.000000   \n",
      "698         0.001655         0.008101         0.000000         0.000000   \n",
      "709         0.052308         0.000000         0.000000         0.000000   \n",
      "712         0.008276         0.000000         0.000000         0.000000   \n",
      "713         0.014435         0.000012         0.000000         0.000000   \n",
      "718         0.044298         0.000000         0.000000         0.000000   \n",
      "730         0.020016         0.000000         0.000000         0.000000   \n",
      "731         0.001551         0.000000         0.000000         0.000000   \n",
      "732         0.000000         0.000000         0.000860         0.001547   \n",
      "734         0.000000         0.000000         0.000000         0.000000   \n",
      "736         0.007518         0.000000         0.003894         0.000000   \n",
      "742         0.000453         0.000000         0.001814         0.000000   \n",
      "743         0.000000         0.000000         0.000000         0.000000   \n",
      "754         0.000000         0.000000         0.000237         0.004251   \n",
      "773         0.000000         0.000000         0.000000         0.009733   \n",
      "776         0.000000         0.000000         0.000000         0.000000   \n",
      "779         0.000000         0.000000         0.000000         0.003483   \n",
      "793         0.000000         0.000000         0.000453         0.000618   \n",
      "800         0.002354         0.000000         0.002564         0.001683   \n",
      "\n",
      "     percent_GROUP_9  percent_GROUP_10  \n",
      "2           0.000111          0.003638  \n",
      "5           0.000000          0.006325  \n",
      "22          0.000000          0.003672  \n",
      "29          0.000841          0.010760  \n",
      "32          0.001851          0.001322  \n",
      "64          0.000325          0.005224  \n",
      "81          0.000000          0.014205  \n",
      "92          0.000000          0.002124  \n",
      "94          0.000000          0.003963  \n",
      "95          0.000000          0.000000  \n",
      "96          0.000000          0.000000  \n",
      "98          0.000000          0.000000  \n",
      "113         0.000000          0.000000  \n",
      "114         0.000000          0.000424  \n",
      "124         0.000000          0.000311  \n",
      "128         0.000000          0.000000  \n",
      "132         0.000000          0.000000  \n",
      "133         0.000000          0.010929  \n",
      "135         0.000000          0.005455  \n",
      "147         0.000000          0.000000  \n",
      "185         0.000000          0.010841  \n",
      "187         0.000000          0.013690  \n",
      "202         0.000000          0.016435  \n",
      "205         0.003969          0.001184  \n",
      "215         0.000000          0.011966  \n",
      "224         0.000000          0.002708  \n",
      "332         0.000000          0.000000  \n",
      "333         0.000000          0.006661  \n",
      "342         0.000000          0.000000  \n",
      "382         0.000000          0.011393  \n",
      "..               ...               ...  \n",
      "626         0.000003          0.012216  \n",
      "629         0.000000          0.014462  \n",
      "633         0.000296          0.005524  \n",
      "647         0.000000          0.008491  \n",
      "659         0.000903          0.012016  \n",
      "665         0.000303          0.016640  \n",
      "675         0.000412          0.005563  \n",
      "677         0.001491          0.005466  \n",
      "683         0.000000          0.001932  \n",
      "688         0.003220          0.005367  \n",
      "691         0.000000          0.000844  \n",
      "697         0.000000          0.000000  \n",
      "698         0.004231          0.017114  \n",
      "709         0.018699          0.000000  \n",
      "712         0.015544          0.000118  \n",
      "713         0.020760          0.000000  \n",
      "718         0.011951          0.000000  \n",
      "730         0.000000          0.007191  \n",
      "731         0.006431          0.006042  \n",
      "732         0.000000          0.000000  \n",
      "734         0.046042          0.003061  \n",
      "736         0.008859          0.000926  \n",
      "742         0.000213          0.007604  \n",
      "743         0.000000          0.008324  \n",
      "754         0.002193          0.011206  \n",
      "773         0.000030          0.001157  \n",
      "776         0.000000          0.015734  \n",
      "779         0.000000          0.004180  \n",
      "793         0.012313          0.004457  \n",
      "800         0.001123          0.009672  \n",
      "\n",
      "[100 rows x 919 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 240.80376792 seconds ---\n"
     ]
    }
   ],
   "source": [
    "df_test_new = dp.df_prep_test(df_test, tfidf_model,NMF_model, TFIDF_feat_model, 'HomeAndKitchen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking out columns that are all 0\n",
    "\n",
    "Before running ensemble method algorithm,  \n",
    "I want to identify any columns that only have value 0 in my training set.  \n",
    "These columns will not affect my prediction results and should be removed to reduce dimensionality of my model.  \n",
    "  \n",
    "In order to do this, I identify these columns from my training dataset first and  \n",
    "removed them from both training and test dataset.  \n",
    "Test dataset may contain columns with zero values that are different from training set.  \n",
    "However, these will be kept in our dataset because we only care about columns with zeros  \n",
    "in our training set during our model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Commercial Ovens', u'Vanities', u'Rimming Salts & Sugars',\n",
      "       u'Ice Machines', u'Bathroom Mirrors', u'Fiber Beds',\n",
      "       u'Cooking Equipment Accessories', u'Gratinee Bowls', u'Cake Testers',\n",
      "       u'Inflatable Pillows', u'Mechanical', u'Splash Guards',\n",
      "       u'Refrigeration Equipment', u'Disposables', u'Lighted Vanity Mirrors',\n",
      "       u'China Cabinets', u'Water Filter Cleaners', u'Restaurant Furniture',\n",
      "       u'Take Out Containers', u'Built-In Wine Cellars', u'Fingertip Towels'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "zero_columns_train = df_train_new.columns[(df_train_new == 0).all()]\n",
    "print zero_columns_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_new = df_train_new.drop(zero_columns_train, 1)\n",
    "df_test_new = df_test_new.drop(zero_columns_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making XGboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing labels for prediction modeling\n",
    "Before running prediction model with XGboost, we want to create labels for our model. \n",
    "For this prediction model, I created a feature called 'helpful_percent'  \n",
    "which indicates percentage of user voted review as helpful review.\n",
    "I want to split this feature into two groups to make my prediction model binary classifier.\n",
    "\n",
    "the function **label_prep** is a function that prepares label feature.\n",
    "It also prints out total number of reviews that belongs LOW and HIGH label class in your data frame.  \n",
    "\n",
    "input:\n",
    "**dp.label_prep( a , b )**\n",
    "a = train or test dataframe.  \n",
    "b = float value that splits label.  \n",
    "the label feature has value HIGH or LOW.  \n",
    "If the 'helpful_precent' is higher than the value of b, label == HIGH.  \n",
    "If the 'helpful_precent' is lower than the value of b, label == LOW.  \n",
    "I usually set this values around 0.75 to 0.9.  \n",
    "What I care most here is predicting HIGH correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  \n",
      "highly helpful count: 59260\n",
      "not helpful count: 10248\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_pickle(\"./preped_videogame_1000_df.pkl\")\n",
    "print \"training data:  \"\n",
    "df_train_new = dp.label_prep(df_train_new, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: \n",
      "highly helpful count: 10444\n",
      "not helpful count: 1823\n"
     ]
    }
   ],
   "source": [
    "print \"test data: \"\n",
    "df_test_new = dp.label_prep(df_test_new,0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjusting number of data in training and test sets\n",
    "Another step you want to apply before applying XGboost.\n",
    "Since training and test dataframe most likely have unbalanced label classes (HIGH and LOW),  \n",
    "we want to balance label classes by randomly select set numbers of reviews from each class.  \n",
    "From the print statement of previous step (label_prep), you know how many reviews exist in both HIGH and LOW label class.  \n",
    "Select a number so that the number of reviews for HIGH and LOW are about same.  \n",
    "  \n",
    "For example:  \n",
    "if label_prep prints out:\n",
    "  \n",
    "highly helpful count: 34290  \n",
    "not helpful count: 25345  \n",
    "\n",
    "I would select number 25000 (if you really want to increase number of reviews, 27500?).  \n",
    "  \n",
    "input:  \n",
    "**df_for_XGBOOST**( a , b )  \n",
    "a = dataframe  \n",
    "b = maximum number of reviews in each label class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y, df_new_train = dp.df_for_XGBOOST(df_train_new,10000)\n",
    "test_X, test_y, df_new_test = dp.df_for_XGBOOST(df_test_new,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost model\n",
    "function **XGBOOSTING** creates XGboost model, fits training dataset and prints out test data accuracy score.\n",
    "\n",
    "inputs:\n",
    "**XGBOOSTING(train_X,test_X,train_y,test_y,xgb_para=[4000,0.15])**\n",
    "a = X train  \n",
    "b = X test  \n",
    "c = label train  \n",
    "d = label test  \n",
    "e = parameters for XGboost. xgb_para = [4000,0.15]  \n",
    "where xgb = XGB.XGBClassifier(n_estimators=xgb_para[0], learning_rate=xgb_para[1])  \n",
    "  \n",
    "  \n",
    "### Random Forest model\n",
    "function **r_forest** runs random frest insted of XGBoost. Only difference is the parameter.  \n",
    "  \n",
    "inputs:  \n",
    "**r_forest(train_X,test_X,train_y,test_y,parameter=[1000,'auto',none])**  \n",
    "parameter = [1000,'auto',None]  \n",
    "where rf = RandomForestClassifier(n_estimators=parameter[0], max_features = parameter[1], max_depth=parameter[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 229.185268164 seconds ---\n",
      "RF score: 76.51%\n"
     ]
    }
   ],
   "source": [
    "model = dp.XGBOOSTING(train_X,test_X,train_y,test_y,xgb_para=[4000,0.15])\n",
    "#model = dp.r_forest(train_X,test_X,train_y,test_y, [1000,50,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost stats (Important Features and confusion matrix)\n",
    "following function prints out Top15 important features of the prediction model,  \n",
    "confusion matrix that is in the markdown format table,  \n",
    "LOW prediction rate and HIGH prediction rate.  \n",
    "\n",
    "input:  \n",
    "**xgb_stats**( a , b , c , d )  \n",
    "a = XGboost model  \n",
    "b = dataframe (an output of df_for_XGBOOST function)  \n",
    "c = test X data  \n",
    "d = test label data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **TOP15 Important Features**  \n",
      "sturdy : 0.584678335779%  \n",
      "away : 0.585385341721%  \n",
      "percent_GROUP_3 : 0.595985233692%  \n",
      "plan : 0.603078315879%  \n",
      "canister : 0.615096497908%  \n",
      "percent_GROUP_8 : 0.836280530402%  \n",
      "percent_GROUP_1 : 0.875366369339%  \n",
      "percent_GROUP_10 : 0.878284937356%  \n",
      "firm : 0.893000387224%  \n",
      "loud : 0.968729776675%  \n",
      "rank_values : 1.06398524065%  \n",
      "main : 1.17321765229%  \n",
      "price : 1.29460566953%  \n",
      "text_length : 2.83935230228%  \n",
      "overall : 8.2429583893%  \n",
      "\n",
      "\n",
      " |                 |       NOT HELPFUL TRUE       |        HIGHLY HELPFUL TRUE        |\n",
      "     |:--------------: | :-------------------:|:-----------------------:|\n",
      "     |       NOT HELPFUL PRED     |        1493.0        |           568.0        |\n",
      "     |        HIGHLY HELPFUL PRED     |        330.0        |           1432.0        |\n",
      "\n",
      "LOW prediction rate: 81.9%\n",
      "HIGH prediction rate: 71.6%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.xgb_stats(model,df_new_test,test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### XGB RESULTS with 75% threshold\n",
    "  \n",
    "n_estimators=2000,learning_rate=0.1,subsample =0.9, max_depth =25, gamma = 0.3, colsample_bytree =0.8, reg_alpha = 0.01  \n",
    "Computation: 2025.37363505 seconds  \n",
    "score: 77.24%  \n",
    " **TOP15 Important Features**  \n",
    "percent_GROUP_5 : 1.06626739725%  \n",
    "overall : 1.06887128204%  \n",
    "plan : 1.08449421823%  \n",
    "tank : 1.10662672669%  \n",
    "canister : 1.14698605612%  \n",
    "unit : 1.20166642591%  \n",
    "bring : 1.30321569741%  \n",
    "percent_GROUP_3 : 1.35008459911%  \n",
    "firm : 1.64041146636%  \n",
    "percent_GROUP_8 : 1.82528309524%  \n",
    "percent_GROUP_1 : 2.2015362978%  \n",
    "text_length : 3.62322628498%  \n",
    "percent_GROUP_10 : 3.6336414516%  \n",
    "price : 3.9552140981%  \n",
    "rank_values : 4.77411784232%  \n",
    "\n",
    "\n",
    " |                 |       NOT HELPFUL TRUE       |        HIGHLY HELPFUL TRUE        |  \n",
    "     |:--------------: | :-------------------:|:-----------------------:|  \n",
    "     |       NOT HELPFUL PRED     |        1426.0        |           473.0        |  \n",
    "     |        HIGHLY HELPFUL PRED     |        397.0        |           1527.0        |  \n",
    "  \n",
    "LOW prediction rate: 78.22%  \n",
    "HIGH prediction rate: 76.35%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Random Forest result with 75% threshold\n",
    "  \n",
    "1000,50,None  \n",
    "224 sec.  \n",
    "Overall accuracy: 76.82%  \n",
    "**TOP15 Important Features**  \n",
    "bring : 0.583035827847%  \n",
    "tank : 0.595895823154%  \n",
    "canister : 0.630979208038%  \n",
    "whatev : 0.656540650705%  \n",
    "percent_GROUP_3 : 0.672279437706%  \n",
    "percent_GROUP_8 : 0.802946732109%  \n",
    "percent_GROUP_10 : 0.885243888022%  \n",
    "percent_GROUP_1 : 0.888022789254%  \n",
    "firm : 0.905402625438%  \n",
    "rank_values : 1.02694375671%  \n",
    "loud : 1.09024337464%  \n",
    "price : 1.33508923173%  \n",
    "main : 1.36355712797%  \n",
    "text_length : 2.80382163106%  \n",
    "overall : 8.20653149646%  \n",
    "\n",
    "\n",
    " |                 |       NOT HELPFUL TRUE       |        HIGHLY HELPFUL TRUE        |  \n",
    "     |:--------------: | :-------------------:|:-----------------------:|  \n",
    "     |       NOT HELPFUL PRED     |        1492.0        |           555.0        |  \n",
    "     |        HIGHLY HELPFUL PRED     |        331.0        |           1445.0        |  \n",
    "\n",
    "LOW prediction rate: 81.84%  \n",
    "HIGH prediction rate: 72.25%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearchcv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'min_child_weight':range(1,6,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation: 24289.086812 seconds  \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gsearch = GridSearchCV(estimator = XGB.XGBClassifier( learning_rate =0.1, n_estimators=2000, max_depth=25,\n",
    " min_child_weight=1, subsample=0.9), param_grid = param_test1, cv=5)\n",
    "gsearch.fit(train_X,train_y)\n",
    "gsearch.best_score_, gsearch.best_params_, gsearch.best_estimator_\n",
    "print(\"Computation: %s seconds  \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'min_child_weight': 1},\n",
       " XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "        gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=25,\n",
       "        min_child_weight=1, missing=None, n_estimators=2000, nthread=-1,\n",
       "        objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "        scale_pos_weight=1, seed=0, silent=True, subsample=0.9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_params_, gsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
